# Set it to false to switch back to conventional for-loop processing (included for comparison).
use_multiprocessing = True

if use_multiprocessing:
    # Disable internal parallelization of OVITO's pipeline system, which otherwise would perform certain
    # computations using all available processor cores. Setting the environment variable OVITO_THREAD_COUNT=1
    # must be done BEFORE importing the ovito module and will restrict OVITO to a single CPU core per process.
    import os
    os.environ["OVITO_THREAD_COUNT"] = "1"

# Boilerplate code generated by OVITO Pro 3.8.5
from ovito.io import *
from ovito.modifiers import *
from ovito.data import *
from ovito.pipeline import *
import sys
import os
import numpy as np
from time import time
import warnings

NATOMS=21952
NREPLICA= sys.argv[1]

DIR = "TRESH_0.4"
BD = "/leonardo_work/IscrB_REACSIM/METALS/NPTX4_FAST"
NFRAMES=5001

_td = f"{BD}/replica_{NREPLICA}/LENS/{DIR}"
OUTD = f"{_td}/TRJ"
os.makedirs(OUTD,exist_ok=True)

OUTD_NOVOID = f"{_td}/TRJ_NOVOID"
os.makedirs(OUTD_NOVOID,exist_ok=True)


def load_and_construct_string(file_path,NATOMS):
    try:
        # Load the data from the file
        data = np.loadtxt(file_path, dtype='int')
        
        # If the file is empty, data will be an empty array
        if data.size == 0:
            ids = []
        else:
            # Ensure the data is in a consistent format
            if data.ndim == 0:
                # Single element case
                ids = [data]
            elif data.ndim == 1:
                # Multiple elements in one dimension
                ids = data.tolist()
            else:
                print("The file format is unexpected.")
                return
        
        # Construct the string based on the IDs
        if not ids:
            result_string = f"ParticleIdentifier == {NATOMS+1}"
        else:
            result_string = " || ".join(f"ParticleIdentifier == {id}" for id in ids)
        
#         print(result_string)
        return result_string, len(ids)

    except OSError as e:
        print(f"Error reading the file: {e}")
    except ValueError as e:
        print(f"Error in file content: {e}")




def process_frame(NFRAME):

    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        STRINGA, n_lens = load_and_construct_string(f"{_td}/IDs_frame{NFRAME}.dat",NATOMS)

    pipeline = import_file(f"{BD}/replica_{NREPLICA}/scnemd.lammpsdump", multiple_frames = True)
    pipeline.modifiers.append(ExpressionSelectionModifier(expression = f"{STRINGA}"))
    # Invert selection:
    pipeline.modifiers.append(InvertSelectionModifier())

    # Delete selected:
    pipeline.modifiers.append(DeleteSelectedModifier())
    export_file(pipeline, f"{OUTD}/frame.{NFRAME}.lammpsdump", "lammps/dump",
    columns = ['Particle Identifier', 'Particle Type','Position.X',
    'Position.Y','Position.Z','Periodic Image.X', 'Periodic Image.Y', 'Periodic Image.Z'],frame=NFRAME)

    if n_lens > 0:
        export_file(pipeline, f"{OUTD_NOVOID}/frame.{NFRAME}.lammpsdump", "lammps/dump",
	columns = ['Particle Identifier', 'Particle Type','Position.X',
	'Position.Y','Position.Z','Periodic Image.X', 'Periodic Image.Y', 'Periodic Image.Z'],frame=NFRAME)


    return 1

# Main program entry point:
if __name__ == '__main__':

    # Measure time for benchmarking purposes.
    from time import time
    t_start = time()

    if use_multiprocessing:

        # Force "spawn" start method on all platforms, because OVITO is not compatible with "fork" method.
        import multiprocessing as mp
        mp.set_start_method('spawn')

        # Create a pool of processes which will process the trajectory frames in parallel.
        with mp.Pool(None) as pool:
            results = list(pool.imap(process_frame, range(NFRAMES))) #range(pipeline.source.num_frames)

    else:

        # Conventional for-loop iterating over all frames of the trajectory and processing one by one.
        results = [process_frame(frame) for frame in range(NFRAMES)]


    t_end = time()

    print(f"Computation took {t_end - t_start} seconds")

